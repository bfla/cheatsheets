{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a599ce-b7e9-4bd2-a403-a1bcd9a43e1a",
   "metadata": {},
   "source": [
    "# NLP Transformers Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee82159-42f6-4943-b821-ad3afcacc0e7",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d0007-cc00-4443-8997-a687d6eca0d9",
   "metadata": {},
   "source": [
    "This project uses Pipenv\n",
    "\n",
    "```bash\n",
    "pipenv install\n",
    "pipenv shell\n",
    ">> jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662621be-d0a8-49c6-80db-b18f42081f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a6314-0c81-4ae2-90be-9b9d9cffbaaf",
   "metadata": {},
   "source": [
    "> ðŸ›‘ Warning: These models are quite large. If you download them, they will take up space in your hard drive and running this notebook locally will require compute resources. It's not really recommended that you run this notebook from start to finish! You can clean these up by running `rm -rf ~/.cache/huggingface/hub/models*`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbded9ac-d17f-4e91-98ec-6eb094c51dc7",
   "metadata": {},
   "source": [
    "## Basic Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de32e36-54a8-4215-bd83-01615e521ce4",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63705a36-e082-43e7-9792-493845430ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/bfla/.local/share/virtualenvs/nlp-transformers-3_mT6cU3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.999743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.999743"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, will use a DistelBERT sentiment analysis model\n",
    "classifier = pipeline('text-classification')\n",
    "text = 'This product is really terrible. I hate it.'\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b8aba-7d6f-4776-a828-c89fd1a297a1",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e604dd6-9ecb-4b76-aa5f-edcbba9d3fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/bfla/.local/share/virtualenvs/nlp-transformers-3_mT6cU3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f21f137d9540b39b56d63f1bb32695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90dcd55252f45efb73a3f3997b179f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0684507cfb6f4d4384bcea8897f8db47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79874e5b59764f76a215457a661e9248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.993974</td>\n",
       "      <td>Luke Skywalker</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999145</td>\n",
       "      <td>Paris</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>France</td>\n",
       "      <td>83</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.998361</td>\n",
       "      <td>Google</td>\n",
       "      <td>119</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score            word  start  end\n",
       "0          PER  0.993974  Luke Skywalker     18   32\n",
       "1          LOC  0.999145           Paris     76   81\n",
       "2          LOC  0.999771          France     83   89\n",
       "3          ORG  0.998361          Google    119  125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger = pipeline('ner', aggregation_strategy='simple')\n",
    "ner_text = 'Hello. My name is Luke Skywalker. My birthday is August 10, 2000. I live in Paris, France. I work for a company called Google.'\n",
    "outputs = ner_tagger(ner_text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533ec8a-d442-49eb-a1ab-79126ef2b52e",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de622fa9-7c1f-4296-8fb5-8376e4fee5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bd0d4bdc1946f388456b9584c0e2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1310a96bfb154b3c85e4a5e5cff4042d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16f99da555a49b7b09f2974adf5db85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8130ed147e664a648a6f07e64a332b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd99351c53524769a99dec3bce28ece7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309721</td>\n",
       "      <td>89</td>\n",
       "      <td>101</td>\n",
       "      <td>heated seats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end        answer\n",
       "0  0.309721     89  101  heated seats"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = pipeline('question-answering')\n",
    "question = 'What does the customer want?'\n",
    "qa_text = 'I have some questions about the 2020 JEEP Grand Cherokee. Does the basic model come with heated seats and a heated steering wheel?'\n",
    "outputs = reader(question=question, context=qa_text)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812ccb5-3165-49be-829c-eded19fac93a",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b724ec-058b-43b6-addf-3b3ff8d78143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Your min_length=56 must be inferior than your max_length=45.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nicomachean Ethics is one of Aristotle's best-known works on ethics. It consists of ten sections, referred to as books, and is closely related to Aristotle's Eudemian Ethics. It\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "summ_text = \"The Nicomachean Ethics is among Aristotle's best-known works on ethics: the science of the good for human life, that which is the goal or end at which all our actions aim.[1]:â€ŠI.2â€Š It consists of ten sections, referred to as books, and is closely related to Aristotle's Eudemian Ethics.\"\n",
    "outputs = summarizer(summ_text, max_length=45, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d3d5a-8908-4183-a740-1d983154f9a0",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff78b555-a157-4660-a4d1-ef9f2ced8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo, wo ist das Badezimmer bitte? - Ich weiÃŸ nicht, wo es ist........................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline('translation_en_to_de', model='Helsinki-NLP/opus-mt-en-de')\n",
    "en_text = 'Hello. Where is the bathroom please?'\n",
    "outputs = translator(en_text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedc269-cc25-41a2-a892-e3c6c079bd89",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b85850b-38fc-4eeb-b2df-20e2f364bf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Customer service response:\n",
      "Dear Customer, I am sorry to hear that your order was mixed up. We've received the problem and there is nothing we can do about it. Please contact us soon to investigate. Thank you again for your patience and please get back as soon as possible.\n",
      "\n",
      "Customer service response:\n",
      "\n",
      "Hello, I found a good-quality pair of scissors and a pair of scissors for an upcoming haircut at an online shop. The items were nicely priced, and when I picked up the scissors they were cut with razor sharpness. A lot of compliments have come to me from customers who have purchased this product. I find the quality of the scissors extremely high. We also want to commend the service by the customer that sent us the scissors. We sent them promptly, and they arrived as promised right on time! Thank you for your patience.\n",
      "\n",
      "Customer service response:\n",
      "\n",
      "Thank-you that your order arrived very promptly. I've worked so hard recently with\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation')\n",
    "text = 'Dear Amazon, last week I ordered an Optimus Prime action figure from your online store. Unfortunately when I opened it, I discovered to my horror that it was a Megatron action figure instead. Can I please exchange it for the action figure that I ordered?'\n",
    "response = 'Dear Customer, I am sorry to hear that your order was mixed up.'\n",
    "prompt = \"\\n\\nCustomer service response:\\n\" + response\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25db70b-62b3-4fa5-96c1-c55ca439c5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
